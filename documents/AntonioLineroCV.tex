\documentclass[11pt]{moderncv}
\usepackage[authoryear]{natbib}

\DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}
\DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf}
\DeclareOldFontCommand{\tt}{\normalfont\ttfamily}{\mathtt}
\DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}
\DeclareOldFontCommand{\it}{\normalfont\itshape}{\mathit}
\DeclareOldFontCommand{\sl}{\normalfont\slshape}{\@nomath\sl}
\DeclareOldFontCommand{\sc}{\normalfont\scshape}{\@nomath\sc}
\DeclareRobustCommand*\cal{\@fontswitch\relax\mathcal}
\DeclareRobustCommand*\mit{\@fontswitch\relax\mathnormal}

\moderncvtheme[blue]{classic}

\usepackage[scale=0.8]{geometry}

\firstname{Antonio}
\familyname{{}Linero}
\title{Assistant Professor \newline Department of Statistics and Data Sciences}
\address{Austin, Texas}{}
\email{antonio.linero@austin.utexas.edu}
\homepage{theodds.github.io}
\extrainfo{\today}

% Define \cvdoublecolumn, which sets its arguments in two columns
% without any labels


\newcounter{pubcounter}
\setcounter{pubcounter}{0}
\newcommand{\docounter}{\stepcounter{pubcounter}\arabic{pubcounter}.}

\newcommand{\cvdoublecolumn}[2]{%
  {}{%
    \begin{minipage}[t]{\listdoubleitemmaincolumnwidth}#1\end{minipage}%
    \hfill%
    \begin{minipage}[t]{\listdoubleitemmaincolumnwidth}#2\end{minipage}%
   }%
}

% usage: \cvreference{name}{address line 1}{address line 2}{address
% line 3}{address line 4}{e-mail address}{phone number} Everything but
% the name is optional If \addresssymbol, \emailsymbol or \phonesymbol
% are specified, they will be used.  (Per default, \addresssymbol
% isn't specified, the other two are specified.)  If you don't like
% the symbols, remove them from the following code, including the
% tilde ~ (space).

\newcommand{\cvreference}[7]{%
    \textbf{#1}\newline% Name
    \ifthenelse{\equal{#2}{}}{}{\addresssymbol~#2\newline}%
    \ifthenelse{\equal{#3}{}}{}{#3\newline}%
    \ifthenelse{\equal{#4}{}}{}{#4\newline}%
    \ifthenelse{\equal{#5}{}}{}{#5\newline}%
    \ifthenelse{\equal{#6}{}}{}{\emailsymbol~\texttt{#6}\newline}%
    \ifthenelse{\equal{#7}{}}{}{\phonesymbol~#7}}

\setlength{\hintscolumnwidth}{0.2\textwidth}

% \cventry{year–year}{Degree}{Institution}{City}{\textit{Grade}}{Description}

\makeatletter
\renewcommand*{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}

\begin{document}
\maketitle

\section{Professional Experience}

\cventry{2018 -- Present}{Assistant Professor}{University of Texas at Austin}{Department of Statistics and Data Sciences}{}{}
\cventry{2015 -- 2018}{Assistant Professor}{Florida State University}
        {Department of Statistics}{}{}

\section{Education}

\cventry{2010--2015}{PhD, Statistics}{University of
  Florida}{}{}{{Dissertation ---  {\em Nonparametric Bayes: Inference Under
  Nonignorable Missingness and Model Selection}}}

\cventry{2005--2009}{BS, Finance}{University of Florida}{}{}{Minor---Statistics}

% \cvitem{}{}

\section{External Funding}

\cvitem{2022--2027}{\emph{CAREER: Foundations for Bayesian Nonparametric Causal
    Inference} (PI). Funded by the National Science Foundation (NSF-DMS
  2144933). Total award \$400,002.} 

\cvitem{2018--2022}{\emph{The Science of Test} (PI Eric Chicken; PI on
  UT Subcontract). Funded by Department of Defense. Total award
  \$478,000.}{}

\cvitem{2017--2020}{\emph{Leveraging Structural Information in Regression Tree
    Ensembles} (PI). Funded by the National Science Foundation (NSF-DMS
  1712870). Total award \$100,000.}{}

\cvitem{2016--2018}{\emph{Functional Analysis Tools (FATs)} (PI Eric Chicken).
  Funded by Department of Defense (SOT-FSU-FATs-16-06). Total award \$246,000.}{}



\section{Awards}

\cventry{Spring 2016}{First Year Assistant Professor Award}{Florida State University}
{}{}{Funding for summer research work.}

\cventry{Spring 2015}{CLAS Dissertation Fellowship}{University of
  Florida}{}{}{Funding for writing of PhD dissertation.}

\cventry{2014}{Statistics Faculty Award}{University of
  Florida}{}{}{Awarded to ``the best graduating PhD student'' in the
  Department of Statistics.}

\cventry{2014}{Laplace Award}{}{}{awarded by the International Society
  for Bayesian Analysis and the Section of Bayesian Statistical
  Science of the American Statistical Association}{For best Bayesian
  student paper.} 

\cventry{2014}{Student Travel Award}{}{}{awarded by the Section of
  Bayesian Statistical Science}{To attend the Joint Statistical
  Meeting.}

\cventry{Fall 2010--Spring 2011}{Mendenhall Fellow}{University of
  Florida}{}{}{Fellowship awarded to top incoming students.}

\cventry{Fall 2010--Spring 2013}{Grinter Fellow}{University of
  Florida}{}{}{Research and graduate program fellowship.}

\section{Service}

\cventry{2022 -- Present}{Nomination Committee Member}{}{}{International Society of Bayesian Analysis}{}

\cventry{2018 -- Present}{Associate Editor}{}{}{Biometrics}{}

\cventry{2021 -- 2023}{ENAR Student Paper Awards Committee Member}{}{}{}{}

\cventry{}{Referee}{}{}{
  American Statistician,
  Annals of Applied Statistics,
  Annals of Statistics,
  Bayesian Analysis,
  Biometrics,
  Biometrika, 
  Biostatistics,
  Computational Statistics and Data Analysis,
  International Journal of Approximate Reasoning,
  Journal of the American Statistical Association,
  Journal of Applied Statistics,
  Journal of Computational and Graphical Statistics,
  Journal of Epidemiology,
  Journal of the Korean Statistical Society,
  Journal of Machine Learning Research,
  Journal of the Royal Statistical Society, Series C.,
  Journal of Statistical Distributions and Applications,
  Journal of Statistical Software,
  Operations Research,
  PLOS One,
  Psychological Methods,
  Sankhya Series A,
  Statistica Sinica,
  Statistical Methods in Medical Research,
  Statistical Science,
  Statistics and Computing,
  Statistics in Medicine,
  Technometrics}{} 

% \cventry{2016}{CM Statistics}{}{}{Chair of session ``Bayesian Methods for
%   Dependent Data''}{}

% \cventry{2014}{ENAR Spring Meeting}{}{}{Chair of session ``Innovative
%   Bayesian Nonparametrics in Biostatistics''}{}

\section{Teaching}

\subsection{At University of Texas at Austin}

\cvitem{\textbf{SDS 348}}{Computational Biology and Bioinformatics. Fall 2020}
\cvitem{\textbf{SDS 383D}}{Statistical Modeling II. Spring 2020, Spring 2021}
\cvitem{\textbf{SDS 322E}}{Elements of Data Science. Fall 2022}

\subsection{At Florida State University}

\cvitem{\textbf{STA5934}}{Bayesian Nonparametrics. Spring 2019}
\cvitem{\textbf{STA4442}}{Introduction to Probability. Fall 2015, Spring 2017, 2018}
\cvitem{\textbf{STA5168}}{Statistics in Applications 3. Fall 2016, 2017, 2018}
\cvitem{\textbf{STA3032}}{Engineering Statistics. Spring 2016}

\subsection{At University of Florida}

\cvitem{\textbf{STA4321}}{Introduction to Probability. Spring 2013}

\section{Students Advised}

\cvitem{}{($\star \rightarrow$ in progress)}

\vspace{0.5em}

\cvitem{}{
  Roumen Varbanov (2018, Co-advisor Eric Chicken),
  Junliang Du (2019, Co-advisor Debajyoti Sinha), 
  Apurva Desai (2020, Co-advisor Adrian Barbu),
  Wright Shamp (2021, Co-advisor Eric Chicken),
  Ding Jiang (2021, Co-advisor Fred Huffer),
  Yinpu Li ($2021$, Co-advisor Debajyoti Sinha),
  Lexi Rene ($2022$, Co-advisor Elizabeth Slate),
  Yanxin Li ($2022$, Co-advisor Stephen Walker)
  Kaizong Ye$^\star$,
  Angela Ting$^\star$.
}

\section{Publications in review}

\cvitem{}{($\star \to$ graduate student)}

\vspace{.5em}

\cvitem{\docounter}{\textbf{Linero, A.R.} Prior and Posterior Checking of Implicit Causal Assumptions. \emph{Submitted to Biometrics.}}

\cvitem{\docounter}{\textbf{Linero, A.R. and Du, J.} Gibbs Priors for Bayesian
  Nonparametric Variable Selection with Weak Learners. \emph{Major Revision at
    Journal of Computational and Graphical Statistics.}}

\cvitem{\docounter}{\textbf{Linero, A.R.} Generalized Bayesian Additive Regression Trees: Beyond Conditional Conjugacy. \emph{Submitted to Journal of the American Statistical Association.}}

\cvitem{\docounter}{Orlandi, V., Murray, J., \textbf{Linero, A.R.}, and Volfovsky, A. (2021+) Density Regression with Bayesian Additive Regression Trees. \emph{Submitted to Journal of the American Statistical Association.}}

\cvitem{\docounter}{ \textbf{Linero, A.R.} (2021+) In Nonparametric and High-Dimensional Models, Bayesian Ignorability is an Informative Prior. \emph{Reject and Resubmit at Journal of the American Statistical Association.}}

\cvitem{\docounter}{
  Rene, L.$^{\star}$, \textbf{Linero, A.R.}, and Slate, E. (2021+) Causal Mediation and Sensitivity Analysis for Mixed Scale Data. \emph{Major Revision at Statistical Methods in Medical Research.} 
}

\cvitem{\docounter}{
  Li, Y.$^{\star}$, \textbf{Linero, A.R.}, and Walker, S.G. (2021+) A Latent Slice Sampler on Multivariate Binary Spaces. \emph{Reject and Resubmit at Journal of Computational and Graphical Statistics.}
}


\cvitem{\docounter}{
  Jiang, D.$^{\star}$, \textbf{Linero, A.R.}, and Zhang, X. (2021+) Envelope Methods for Missing Response Data in Multivariate Linear Models. \emph{Submitted to the Canadian Journal of Statistics.}
}


\cvitem{\docounter}{
   Um, S.$^\star$, \textbf{Linero, A.R.}, Sinha, D., and Bandyopadhyay, D. (2021+) Bayesian Additive Regression Trees for Multivariate Skewed Responses. \emph{Major Revision at Statistics in Medicine.}
}



% \cvitem{\docounter}{
%   Doss, H. and \textbf{Linero, A.R.} (2020+) A Fully-Bayes Approach to Empirical Bayes Inference and Sensitivity Analysis.
%   \emph{Submitted.}
% }


\section{Publications in press}

\setcounter{pubcounter}{0}

\cvitem{}{($\star \to$ graduate student)}
\vspace{.5em}


\cvitem{\docounter}{\textbf{Linero A. R} and Antonelli, J.L. (2021+) The How and Why of Bayesian Nonparametric Causal Inference. \emph{To appear in WIREs: Computational Statistics.}}

\cvitem{\docounter}{\textbf{Linero, A.R.} and Zhang, Q. Mediation Analysis using Bayesian Tree Ensembles. \emph{To appear in Psychological Methods.}}

\cvitem{\docounter}{ Li, Y.$^{\star}$, \textbf{Linero, A.R.}, and Murray, J.S.
  (2020+) Adaptive Conditional Distribution Estimation with Bayesian Decision
  Tree Ensembles. \emph{To appear in Journal of the American Statistical Association}.}

\cvitem{\docounter}{
  \textbf{Linero, A.R.} and Du, J. (2021) Variable Selection for Bayesian Decision Tree Ensembles. In Tadesse, M. and Vanucci, M. (Eds.)  \emph{Handbook of Bayesian Variable Selection}. Chapman and Hall/CRC.
}

\cvitem{\docounter}{
  Wright, S.$^{\star}$, \textbf{Linero, A.R.}, and Chicken, E. (2021+) Bayesian
  Sequential Monitoring of Density Estimates. \emph{To appear in Quality and Reliability Engineering International.}
}


\cvitem{\docounter}{ 
  \textbf{Linero, A.R.}, Basak, P.$^{\star}$, Li, Y.$^{\star}$, and Sinha, D. (2021) Bayesian Survival Tree Ensembles with Submodel Shrinkage. \emph{To appear in Bayesian Analysis}
}


\cvitem{\docounter}{
  \textbf{Linero, A.R.} (2021) Simulation-Based Estimators of Analytically Intractable
  Causal Effects. \emph{To appear in Biometrics.}
}


\cvitem{\docounter}{ 
  Basak, P.$^{\star}$, \textbf{Linero, A.R.}, Sinha, D., and Lipsitz, S.R.
  (2021) Semiparametric analysis of clustered interval-censored survival data using Soft Bayesian Additive Regression Trees (SBART). \emph{To appear in Biometrics.}}


\cvitem{\docounter}{Varbanov, R.$^{\star}$, Shamp, W.$^{\star}$, Chicken, E, \textbf{Linero, A.R.}, Yang, Y. (2020)
  Computationally Efficient Bayesian Sequential Function Monitoring. 
  \emph{Journal of Quality Technology.}
}

\cvitem{\docounter}{
  \textbf{Linero, A.R.}, Sinha, D., and Lipsitz, S.R. (2020) Semiparametric Mixed-Scale Models Using Shared Bayesian Forests. 
  \emph{Biometrics}, \textbf{76}(1), 131--144. 
}

\cvitem{\docounter}{Hill, J., \textbf{Linero, A.R.}, and Murray, J. (2020) Bayesian Additive Regression Trees: A Review and Look Forward. \emph{Annual Review of Statistics and Its Application}, \textbf{7}(1), 251--278.}

\cvitem{\docounter}{ Du, J.$^{\star}$ and \textbf{Linero A.R.}, (2019) Incorporating Grouping Information into Bayesian Decision Tree Ensembles. In \emph{Proceedings of the 36th International Conference on Machine Learning (ICML)}. }

\cvitem{\docounter}{
  Du, J.$^{\star}$ and \textbf{Linero A.R.}, (2019) Interaction Detection with Bayesian Decision Tree Ensembles. 
  In \emph{Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)}.
}

\cvitem{\docounter}{Varbanov, R.$^{\star}$, Chicken, E., \textbf{Linero, A.R.}, and Yang, Y. (2019)
  A Bayesian Approach to Sequential Monitoring of Nonlinear Profiles Using Wavelets. \emph{Quality and Reliability Engineering International}, \textbf{35}(3), 761--775.}

\cvitem{\docounter}{\textbf{Linero, A.R.} and Yang, Y. (2018) Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity. \emph{Journal of the Royal Statistical Society, Series B,} \textbf{80}(5), 1087--1110.}

\cvitem{\docounter}{\textbf{Linero, A.R.}, Bradley, J.R, and Desai, A.S.$^{\star}$ (2018) Multi-rubric Models for
  Ordinal Spatial Data with Application to Online Ratings. \emph{Annals of Applied Statistics,} \textbf{12}(4), 2054--2074.}

\cvitem{\docounter}{\textbf{Linero, A.R.} and Daniels, M.J. (2018)  Bayesian Approaches for Missing Not at Random Outcome Data: The Role of Identifying Restrictions.
  \emph{Statistical Science,} \textbf{33}(2), 198--213.}

\cvitem{\docounter}{\textbf{Linero, A.R.} (2018) Bayesian regression trees for high
  dimensional prediction and variable selection. \emph{Journal of the American
    Statistical Association,} \textbf{113}(522), 626--636}

\cvitem{\docounter}{\textbf{Linero, A.R.} (2017) A Review of Tree-Based Bayesian Methods. \emph{Communications for Statistical Applications and Methods,} \textbf{24}(6), 543--559.}

\cvitem{\docounter}{Varbanov, R.$^{\star}$, Chicken, E., and \textbf{Linero, A.R.} (2017)
  Wavelet-Based Bayesian Profile Monitoring. \emph{Proceedings of
    the 2017 Industrial and Systems Engineering Research Conference.}}

\cvitem{\docounter}{\textbf{Linero, A.R.} (2017) Bayesian Nonparametric Analysis of
  Longitudinal Studies in the Presence of Informative Missingness.
  \emph{Biometrika,} \textbf{104}(2), 371--341}


\cvitem{\docounter}{
  Piekarewicz, J., \textbf{Linero, A.R.}, Giuliani, P., and Chicken, E. (2016)
  The power of two: Assessing the impact of a second measurement of the weak-charge
  form factor of \(^{208}\textnormal{Pb}\). \emph{Physical Reviews C,}
  \textbf{94}(3), 034316.
}

\cvitem{\docounter}{Daniels, M.J. and {\bf Linero, A.R.} (2015) Bayesian
  nonparametrics for missing data in longitudinal clinical
  trials. In {\em Nonparametric Bayesian Inference in Biostatistics.}}

\cvitem{\docounter}{{\bf Linero, A.R.} and Daniels, M.J. (2015) A flexible
  Bayesian approach to monotone missing data in longitudinal studies
  with nonignorable missingness with application to an acute
  schizophrenia clinical trial. {\em Journal of the American
    Statistical Association,} {\bf 110}(509), 45--55.}

\cvitem{\docounter}{{\bf Linero, A.R} and Rosalsky, A. (2013) On the Toeplitz
  lemma, convergence in probability, and mean convergence. {\em Stochastic
  Analysis and Applications,} {\bf 31}(4), 684-694.}
  

% \nocite{*}
% \bibliographystyle{unsrt}
% \bibliographystyle{apalike}
% \bibliographystyle{unsrtnat}
% \bibliography{publications}


% \section{Manuscripts in Preparation}

% \cvitem{}{Bradley, J.R., \textbf{Linero, A.R.} and Chicken, E.K. A
%   repeated--measures multivariate spatio--temporal mixed effects model for
%   ordinal data.}

% \cvitem{}{{\bf Linero, A.R.} and Doss, H. A Fully-Bayes Approach to Empirical
%   Bayes Inference and Bayesian Sensitivity Analysis.}

% \section{Invited Presentations}

% \cvitem{01/12/2015}{Flexible Bayesian Analysis in the Presence of
%   Nonignorable Missingness. {\em Florida State University}}
% \cvitem{01/20/2015}{Flexible Bayesian Analysis in the Presence of
%   Nonignorable Missingness. {\em Arizona State University}}
% \cvitem{01/29/2015}{Flexible Bayesian Analysis in the Presence of
%   Nonignorable Missingness. {\em University of Illinois at Urbana Champaign}}
% \cvitem{02/08/2015}{Flexible Bayesian Analysis in the Presence of
%   Nonignorable Missingness. {\em Texas A\&M University}}


\section{Presentations}

\subsection{Short Courses}

\cventry{6/26/2022}{ISBA}{Bayesian Nonparametric Causal Inference}{with Michael Daniels and Jason Roy}{}{}
\cventry{6/27/2021}{ISBA}{Advanced Topics in Variable Selection and Model Averaging}{with Joseph Antonelli}{}{}

\subsection{Invited}

\cventry{01/12/2022}{ISBA Section on Biostatistics and Pharmaceutical Statistics}{Bayesian Survival Tree Ensembles with Submodel Shrinkage}{}{}{}
\cventry{11/30/2021}{Binghamton University}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{9/17/2021}{Universidad Miguel Hernández de Elche}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{5/06/2021}{Bocconi University}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{3/15/2021}{Rice University}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{2/12/2021}{University of Louisville}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{12/15/2020}{ICSA}{BART Methods for Fully-Nonparametric Problems}{}{}{}
\cventry{3/23/2020}{ENAR}{Simulation-Based Estimators of Intractable Causal Effects}{}{}{}
\cventry{6/04/2019}{Ohio State University}{Bayesian Nonparametric Methods for Longitudinal Outcomes Missing Not at Random}{}{}{}
\cventry{5/24/2019}{Virginia Tech}{Finding and Leveraging Structure using Bayesian Decision Tree Ensembles}{}{}{}
\cventry{2/05/2019}{University of Texas at Austin}{Theory and Practice for Bayesian Regression Tree Ensembles}{}{}{}
\cventry{1/24/2019}{University of Michigan}{Theory and Practice for Bayesian Regression Tree Ensembles}{}{}{}
\cventry{1/22/2019}{University of Minnesota}{Theory and Practice for Bayesian Regression Tree Ensembles}{}{}{}
\cventry{1/11/2019}{Duke University}{Theory and Practice for Bayesian Regression Tree Ensembles}{}{}{}
\cventry{1/08/2019}{University of Florida}{Theory and Practice for Bayesian Regression Tree Ensembles}{}{}{}

\cventry{12/15/2018}{CM Statistics}{Finding and Leveraging Structure with Bayesian Decision Tree
    Ensembles}{}{}{}

\cventry{7/30/2018}{JSM}{Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity}{}{}{}

\cventry{6/11/2018}{ISNPS}{Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity}{}{}{}

\cventry{5/19/2018}{IISA}{Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity}{}{}{}

\cventry{12/17/2017}{CM Statistics}{Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity}{}{}{}

\cventry{11/3/2017}{UT Austin}{Bayesian Regression Tree Ensembles that Adapt to Smoothness and Sparsity}{}{}{}

\cventry{8/1/2017}{Joint Statistical Meeting}
{Sensitivity Analysis for Longitudinal Clinical Trials with Nonmonotone Missingness}{}{}{}

\cventry{7/17/2017}{EcoSta}{Bayesian regression trees for high-dimensional
  prediction and variable selection}{}{}{}

\cventry{12/10/2016}{CM Statistics}{Bayesian Nonparametric Analysis of
  Longitudinal Studies with Informative Missingness}{}{}{}

\cventry{9/29/2016}{University of Florida Statistics Symposium}{Bayesian
  Regression Trees for High Dimensional Prediction and Variable Selection}{}{}{}

\cventry{6/12/2016}{ICSA Applied Statistics Symposium}{Bayesian Regression Trees
  for High Dimensional Prediction and Variable Selection}{}{}{}

\cventry{2/11/2015}{University of California at Irvine}{Flexible Bayesian
  Analysis in the Presence of Nonignorable Missingness}{}{}{}

\cventry{2/9/2015}{Texas A\&M University}{Flexible Bayesian
  Analysis in the Presence of Nonignorable Missingness}{}{}{}

\cventry{1/28/2015}{University of Illinois at
  Urbana-Champaign}{Flexible Bayesian Analysis in the Presence of
  Nonignorable Missingness}{}{}{}

\cventry{1/20/2015}{Arizona State University}{Flexible Bayesian
  Analysis in the Presence of Nonignorable Missingness}{}{}{}

\cventry{1/12/2015}{Florida State University}{Flexible Bayesian
  Analysis in the Presence of Nonignorable Missingness}{}{}{}

\subsection{Contributed}

\cventry{2014}{Joint Statistical Meeting}{A Flexible Bayesian Approach
  to Monotone Missing Data in Longitudinal Studies with Informative
  Dropout with Application to a Schizophrenia Clinical Trial}{}{}{}


% \section{Technical Skills}

% \cvitem{{\em Languages \& Software}}{R, BUGS/JAGS/STAN, C++, Python, \LaTeX,
%   Matlab/Octave, Julia, Linux/Windows/OSX}

% \section{Research Interests}

% \cvitem{}{Applications of Bayesian methods to problems in
%   Biostatistics and machine learning.}  

% \cvitem{}{Inference in longitudinal studies with
%   missing data and causal inference.}

% \cvitem{}{Bayesian nonparametrics and semiparametrics.}

% \cvitem{}{Computational issues associated with the above.}

%\section{References}
%
%\cvdoublecolumn{
%  \cvreference{Michael Daniels}
%  {Section of Integrative Biology, Department of Statistics \& Data Sciences}
%  {University of Texas at Austin}
%  {Austin, TX}
%  {}
%  {mjdaniels@austin.utexas.edu}
%  {512-471-4128}
%  \\[1em] \ \\
%  \cvreference{Malay Ghosh}
%  {Department of Statistics}
%  {University of Florida}
%  {}
%  {Gainesville, Florida}
%  {ghoshm@stat.ufl.edu}
%  {352-273-2992}
%  \\[1em] \ \\
%  \cvreference{Nikolay Bliznyuk}
%  {Institute of Food and Agricultural Sciences, Statistics Unit}
%  {University of Florida} 
%  {}
%  {Gainesville, Florida}
%  {nbliznyuk@ufl.edu}
%  {352-392-1946}
%}
%{\cvreference{Hani Doss}
%  {Department of Statistics}
%  {University of Florida}
%  {}
%  {Gainesville, Florida}
%  {doss@stat.ufl.edu }
%  {352-273-2991 }
%  \\ \ \\ \ \\ \ \\ \
%  \cvreference{Andrew Rosalsky}
%  {Department of Statistics}
%  {University of Florida}
%  {Gainesville, Florida}
%  {}
%  {rosalsky@stat.ufl.edu}
%  {352-273-2983}
%}

\end{document}

%  LocalWords:  Statistica Sinica Nonparametric
